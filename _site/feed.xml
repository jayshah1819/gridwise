<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/gridwise/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/gridwise/" rel="alternate" type="text/html" /><updated>2025-11-24T19:39:34-05:00</updated><id>http://localhost:4000/gridwise/feed.xml</id><title type="html">Gridwise</title><subtitle>WebGPU compute primitives in JavaScript</subtitle><entry><title type="html">Gridwise Scan and Reduce</title><link href="http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/" rel="alternate" type="text/html" title="Gridwise Scan and Reduce" /><published>2025-09-16T00:00:00-04:00</published><updated>2025-09-16T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/"><![CDATA[<p><a href="https://en.wikipedia.org/wiki/Prefix_sum">Scan</a> (parallel prefix) is a fundamental parallel compute primitive useful in both other primitives as well as a wide range of application domains. (The <a href="https://en.wikipedia.org/wiki/Prefix_sum#Applications">Wikipedia page</a> describes many possible uses of scan.) Here we describe how our implementation works and how it is used in Gridwise. We published a <a href="https://dl.acm.org/doi/10.1145/3694906.3743326">paper on our scan implementation</a> at SPAA 2025. Here we instead aim for a higher-level, more informal description of our implementation.</p>

<h2 id="terminology">Terminology</h2>

<p>Scan inputs an array of <em>n</em> data elements and outputs an array of the same size. Output element <em>i</em> is the “sum” of the input elements up to element <em>i</em>. More generally, that “sum” operator can be any <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a> (a binary operation with an identity element). If the operator is addition, scan is often called prefix-sum, but we can also compute a prefix-multiplication, prefix-max or -min, or many other operators. For simplicity, we will use “sum” and addition in this article. (Gridwise supports any user-specified monoid.)</p>

<p>We also use the term “reduce”, where a reduction of a set of inputs is the “sum” of all of those elements.</p>

<p>Finally, scans have two variants, exclusive and inclusive. Each output element of an <em>exclusive</em> scan is the sum of all previous items in the input, not including the current item. (<code class="language-plaintext highlighter-rouge">exclusive_out[i] = sum(in[0:i-1]).</code>) Each output element of an <em>inclusive</em> scan is the sum of all previous items in the input, up to and including the current item. (<code class="language-plaintext highlighter-rouge">inclusive_out[i] = sum(in[0:i]).</code>)</p>

<h2 id="gpu-scan-background">GPU Scan Background</h2>

<p>On GPUs, scan performance is bound by memory bandwidth. The best GPU scan implementations fully saturate the GPU’s memory system. Thus the best GPU scan implementations are those that use algorithms that require the fewest accesses to memory. The “classic” GPU way to compute scan is to divide the input into tiles, compute the reduction of all elements in each tile, compute the prefix sum of those per-tile reductions, then use the values of that per-tile prefix sum as inputs into a blockwise scan of each individual tile. This strategy is called <em>reduce-then-scan</em>. The details aren’t important; what is important is that for an <em>n</em>-element scan, we incur 3<em>n</em> memory accesses (<em>n</em> for the per-block reduction and 2<em>n</em> to read the input/write the output in the blockwise scan).</p>

<p>In 2015, Yan et al. introduced an alternate GPU-scan implementation, <a href="https://dl.acm.org/doi/10.1145/2442516.2442539">StreamScan</a>, which required only 2<em>n</em> memory accesses. Like reduce-then-scan, StreamScan computes a reduction for each input tile, but unlike reduce-then-scan, StreamScan then <em>serializes</em> the scan of the per-tile values across tile processors. This approach is called a <em>chained scan</em>. Each tile processor must wait for its predecessor to compute the reduction of all elements up to and including the predecessor’s tile. Then the tile adds its tile reduction to the global reduction and passes it to the next tile’s processor, then uses the partial sum to complete the scan of its tile. The key data structure here is the carry chain, which stores the inclusive scan of the tile reductions. The most important aspect of this implementation is that it only requires reading and writing each element once and thus incurs only 2<em>n</em> memory references, the theoretical minimum.</p>

<p>(All of the above is covered in great detail in our <a href="https://dl.acm.org/doi/10.1145/3694906.3743326">SPAA 2025 paper</a>.)</p>

<p>In an ideal world, all tile processors could run in lockstep and have equal access to memory bandwidth. However, tiles contend with each other for access to memory, and tile processors may be working on multiple tiles simultaneously. Tiles thus don’t run in lockstep; some later tiles may finish before earlier tiles, and thus have to wait for those tiles to finish. This waiting causes performance loss. In 2016, <a href="https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back">Merrill and Garland</a> addressed this performance loss on NVIDIA hardware by enabling stalled tiles to “look back” into the carry chain to fetch the necessary values to compute their carry-chain element. This change ensured that a single stalled tile did not halt the entire scan computation, allowing <a href="https://docs.nvidia.com/cuda/cub/index.html">their implementation</a> to run at maximum throughput. CUB scan is as fast as a memory copy.</p>

<h2 id="decoupled-lookback-and-forward-progress-guarantees">Decoupled Lookback and Forward Progress Guarantees</h2>

<p>NVIDIA GPUs make a <em>forward progress guarantee</em>: once a processor begins to process a tile, it is guaranteed to make progress on that tile; the GPU scheduler ensures the processor will be allocated compute time to move forward on the processing of its tile. This guarantee is necessary for the correctness of Merrill and Garland’s implementation of decoupled lookback.</p>

<p>Unfortunately, not all GPUs provide this forward progress guarantee. <a href="https://dl.acm.org/doi/10.1145/3485508">Apple and ARM GPUs do not.</a> At any point in the scan computation, some tiles are computing a result and other tiles are waiting for a previous tile to finish its computation and write it into the carry chain. Without the forward-progress guarantee, the computing tiles may be fully blocked by waiting tiles and never make progress, leading to a completely stalled computation. On Apple hardware, as we found during the development of our scan primitive, this locks up the entire machine.</p>

<p>Deploying a WebGPU implementation that depends on a forward-progress guarantee is thus not a viable option.</p>

<h2 id="gridwises-scan-and-reduce-implementations">Gridwise’s Scan and Reduce Implementations</h2>

<h3 id="gridwises-scan">Gridwise’s Scan</h3>

<p>Gridwise implements a chained scan that does not require forward-progress guarantees. It does so in a high-performance way that allows scan to run at full memory bandwidth, even on hardware without forward-progress guarantees. Merrill and Garland’s lookback strategy allows a stalled tile processor to look back into the carry chain; we add fallback capability to allow a stalled tile processor to redundantly compute per-tile reductions, and to do so using the full parallelism of the stalled tile processor.</p>

<p>Lookback and fallback were challenging to implement correctly.</p>

<h3 id="gridwises-reduce">Gridwise’s Reduce</h3>

<p>The carry chain in a chained scan stores the inclusive scan of the reduction of each tile. The last element in that carry chain is the sum of all input tiles and is thus the reduction of the entire input. A reduce can thus be implemented using the existing scan machinery (and run at full memory bandwidth). A traditional reduce implementation (computing tile reductions in parallel then reducing the tile reductions into a single value) would likely run just as fast, but would require a different implementation, so we have chosen to use the chained-scan implementation as Gridwise’s reduce. When configured as a reduction primitive, our scan implementation leaves out any scan-specific computation (e.g., we don’t have to compute the final per-tile scan).</p>

<h3 id="leveraging-subgroups">Leveraging Subgroups</h3>

<p>WebGPU’s optional <a href="https://www.w3.org/TR/webgpu/#subgroups">subgroups</a> feature enables WebGPU programs to use SIMD instructions within a workgroup. These can deliver significant performance gains for several reasons: they leverage custom hardware for the computation itself; they do not have to route data through workgroup memory; they require one hardware instruction to do what would take many hardware instructions in emulation; and they require fewer barriers. Gridwise has some, but incompletely deployed, <a href="subgroup-strategy.html">support for emulating SIMD instructions</a>. Our initial performance testing indicated that scan was 2.5x slower using subgroup emulation vs. using subgroup hardware.</p>

<p>It is possible that the fastest scan and reduce implementations in the absence of subgroup hardware are not chained ones. We have not investigated this at all. In general, in Gridwise, we expect that subgroup operations are available, and we use them to reduce across subgroups and workgroups, to broadcast information from one thread to others, and to compute local subgroup-sized scans as part of workgroup scans.</p>

<h2 id="configuring-and-calling-gridwise-scan-and-reduce">Configuring and Calling Gridwise Scan and Reduce</h2>

<h3 id="defining-the-primitive">Defining the primitive</h3>

<p>Declare the scan or reduce primitive as an instance of the <code class="language-plaintext highlighter-rouge">DLDFScan</code> class.  An example scan declaration:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">datatype</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">u32</span><span class="dl">"</span><span class="p">;</span> <span class="c1">// or "i32" or "f32"</span>
<span class="kd">const</span> <span class="nx">dldfscanPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">DLDFScan</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">binop</span><span class="p">:</span> <span class="k">new</span> <span class="nx">BinOpAdd</span><span class="p">({</span> <span class="nx">datatype</span> <span class="p">}),</span>
  <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">exclusive</span><span class="dl">"</span><span class="p">,</span>
  <span class="nx">datatype</span><span class="p">,</span> <span class="c1">// use the "datatype" string defined above</span>
  <span class="na">gputimestamps</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<p>The argument is a JS object and its members may include:</p>

<ul>
  <li><strong>device</strong> (required): the GPU device on which this primitive will run.</li>
  <li><strong>datatype</strong> (required): Scans need to specify the datatype that can be scanned. Currently we support the (WGSL) types “u32”, “i32”, and “f32”, specified as strings. It is definitely possible to support more complex datatypes (e.g., structs), but this would take non-trivial engineering work.</li>
  <li><strong>binop</strong> (required): the “binary operation” aka a <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a>, specified as a combination of a datatype and a binary operator that operates on that datatype. The core scan implementation is agnostic as to the binary operation; the <code class="language-plaintext highlighter-rouge">binop</code> supplies that operation. The binop class is described in more detail <a href="binop.html">here</a>.</li>
  <li><strong>type</strong>: any of <code class="language-plaintext highlighter-rouge">"exclusive"</code>, <code class="language-plaintext highlighter-rouge">"inclusive"</code>, or <code class="language-plaintext highlighter-rouge">"reduce"</code>. Default is <code class="language-plaintext highlighter-rouge">"exclusive"</code>.</li>
  <li><strong>datatype</strong> (required): currently, any WGSL scalar primitive type (<code class="language-plaintext highlighter-rouge">"u32"</code>, <code class="language-plaintext highlighter-rouge">"i32"</code>, or <code class="language-plaintext highlighter-rouge">"f32"</code>). Scan and reduce could be extended to other datatypes with some engineering effort.</li>
  <li><strong>gputimestamps</strong>: enable GPU timestamps for the primitive’s kernel calls.</li>
</ul>

<h3 id="configuring-the-primitive">Configuring the primitive</h3>

<p>Once the primitive is <em>defined</em>, it must then be <em>configured</em>. The primitive knows that it requires an input and output buffer, named <code class="language-plaintext highlighter-rouge">inputBuffer</code> and <code class="language-plaintext highlighter-rouge">outputBuffer</code>. (We use our <a href="buffer.html"><code class="language-plaintext highlighter-rouge">Buffer</code> class</a> for this.) We configure the primitive by registering data buffers with the primitive. This can be done either with a <code class="language-plaintext highlighter-rouge">primitive.registerBuffer()</code> call or as an argument to the <code class="language-plaintext highlighter-rouge">execute</code> call. (The former is preferred if we need to register the buffer(s) once and then call <code class="language-plaintext highlighter-rouge">execute</code> many times.)</p>

<p>To register a buffer, simply call <code class="language-plaintext highlighter-rouge">primitive.registerBuffer(buffer)</code>, where <code class="language-plaintext highlighter-rouge">buffer.label</code> is either <code class="language-plaintext highlighter-rouge">inputBuffer</code> or <code class="language-plaintext highlighter-rouge">outputBuffer</code>. The below code creates a <code class="language-plaintext highlighter-rouge">Buffer</code> then registers it.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">inputLength</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">20</span><span class="p">;</span>
<span class="nx">testInputBuffer</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Buffer</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">datatype</span><span class="p">:</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">length</span><span class="p">:</span> <span class="nx">inputLength</span><span class="p">,</span>
  <span class="na">label</span><span class="p">:</span> <span class="dl">"</span><span class="s2">inputBuffer</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">createCPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeCPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* fill with default data */</span><span class="p">,</span>
  <span class="na">createGPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeGPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* with CPU data */</span><span class="p">,</span>
  <span class="na">createMappableGPUBuffer</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span> <span class="cm">/* never reading this back */</span>
<span class="p">});</span>
<span class="nx">primitdldfscanPrimitiveive</span><span class="p">.</span><span class="nx">registerBuffer</span><span class="p">(</span><span class="nx">testInputBuffer</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="calling-scan-or-reduce">Calling scan or reduce</h3>

<p>Once the primitive is defined and configured, simply call its <code class="language-plaintext highlighter-rouge">execute()</code> method.</p>

<p>If you have not yet registered buffers, you can specify them in the argument object as <code class="language-plaintext highlighter-rouge">inputBuffer</code> and <code class="language-plaintext highlighter-rouge">outputBuffer</code>.</p>

<p>Other possible arguments (which are timing-specific and thus which you are unlikely to use unless you are benchmarking) are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">trials</code> with an integer argument. This will run the kernel(s) that number of times. Default: 1.</li>
  <li><code class="language-plaintext highlighter-rouge">enableGPUTiming</code> with either true or false. If true, please ensure that the device has a set of required features that include <code class="language-plaintext highlighter-rouge">timestamp-query</code>. Default: false.</li>
  <li><code class="language-plaintext highlighter-rouge">enableCPUTiming</code> with either true or false. Default: false.</li>
</ul>

<p>Note that <code class="language-plaintext highlighter-rouge">execute()</code> is declared <code class="language-plaintext highlighter-rouge">async</code>.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">();</span>
<span class="c1">// or, if we want to specify buffers only when execute is called</span>
<span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">inputBuffer</span><span class="p">:</span> <span class="nx">mySrcBuffer</span><span class="p">,</span>
  <span class="na">outputBuffer</span><span class="p">:</span> <span class="nx">myDestBuffer</span><span class="p">,</span>
<span class="p">});</span>
<span class="c1">// or (maybe if you're benchmarking)</span>
<span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">trials</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="na">enableGPUTiming</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="na">enableCPUTiming</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<h2 id="usage-and-performance-notes">Usage and performance notes</h2>

<p>Input lengths <em>must be</em> a multiple of 4. Pad the end of your input array with enough identity elements to make this work. (This is because internally, we use <code class="language-plaintext highlighter-rouge">vec4</code>s for computation.)</p>

<p>Scan has had extensive performance testing and the defaults are fairly stable across different GPUs. The workgroup size, for instance, is set to 256. This particular iteration of the scan kernel has barely been tested with other workgroup sizes and they are unlikely to work out of the box.</p>

<p>If we extended scan to larger datatypes (beyond 32 bits), we expect that workgroup memory consumption would become an issue. We expect we would have to reduce workgroup size accordingly.</p>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Understand scan (parallel prefix) and reduce operations - fundamental parallel compute primitives for high-performance applications.]]></summary></entry><entry><title type="html">Gridwise’s Buffer Class</title><link href="http://localhost:4000/gridwise/docs/2025/09/16/buffer/" rel="alternate" type="text/html" title="Gridwise’s Buffer Class" /><published>2025-09-16T00:00:00-04:00</published><updated>2025-09-16T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/09/16/buffer</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/09/16/buffer/"><![CDATA[<p>During Gridwise’s development, we found a need to encapsulate the concept of a single wad of data that spans CPU and GPU. We call this class <code class="language-plaintext highlighter-rouge">Buffer</code>. It contains both a CPU-side JS typed array and a GPU-side <code class="language-plaintext highlighter-rouge">GPUBuffer</code>. The abstraction is that these two objects are (roughly) consistent with each other (they are not meant to store two logically different objects).</p>

<p>We believe this is an object whose design could be revisited and improved, because it is generally useful in WebGPU primitive development and more generally across WebGPU development. We welcome a redesign. For that purpose, we list our use cases:</p>

<ul>
  <li>We want to couple CPU and GPU buffers that store the same logical data as one logical entity (here, a <code class="language-plaintext highlighter-rouge">Buffer</code> class). The class should be able to copy data between them easily.
    <ul>
      <li>On the CPU side, we want to use a JavaScript typed array.</li>
      <li>On the GPU side, we want to use a WebGPU <code class="language-plaintext highlighter-rouge">GPUBuffer</code>. We note a <code class="language-plaintext highlighter-rouge">GPUBuffer</code> can be a subset of a GPU-side allocation.</li>
    </ul>
  </li>
  <li>We want to allow initializing this <code class="language-plaintext highlighter-rouge">Buffer</code> in multiple flexible ways. For instance, we should be able to initialize a <code class="language-plaintext highlighter-rouge">Buffer</code> using an existing <code class="language-plaintext highlighter-rouge">GPUBuffer</code>, or alternatively ask the <code class="language-plaintext highlighter-rouge">Buffer</code> constructor to allocate one.</li>
  <li>We need to generate data on the CPU for testing, storing it in the (CPU) buffer. We wish to support different methods for data generation (for instance, random numbers within a range, or a dataset where <code class="language-plaintext highlighter-rouge">buffer[i] = i</code>).</li>
  <li>We want to hide WebGPU details if possible (for instance, the call to create a <code class="language-plaintext highlighter-rouge">GPUBuffer</code>, the call to copy data between CPU and GPU).</li>
  <li>The <code class="language-plaintext highlighter-rouge">Buffer</code> needs a label so it can be associated with Gridwise primitives.</li>
  <li>At least one of our primitives (sort) writes its GPU output on top of its GPU input. A <code class="language-plaintext highlighter-rouge">Buffer</code> class must support this and additionally store the original (CPU) input for correctness validation.</li>
  <li>We want to support querying a <code class="language-plaintext highlighter-rouge">Buffer</code> for both:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">size</code> (the number of bytes in the buffer)</li>
      <li><code class="language-plaintext highlighter-rouge">length</code> (the number of elements in the buffer)</li>
    </ul>
  </li>
</ul>

<h2 id="buffer-class-documentation"><code class="language-plaintext highlighter-rouge">Buffer</code> Class documentation</h2>

<h2 id="constructor">Constructor</h2>

<h3 id="constructorargs"><code class="language-plaintext highlighter-rouge">constructor(args)</code></h3>

<p>This creates a new <code class="language-plaintext highlighter-rouge">Buffer</code> instance, using the properties of the <strong><code class="language-plaintext highlighter-rouge">args</code></strong> object to configure the buffer.</p>

<p><strong>Arguments:</strong></p>

<p>The constructor takes a single <strong><code class="language-plaintext highlighter-rouge">args</code></strong> object with these optional properties:</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">label</code></strong>: <code class="language-plaintext highlighter-rouge">string</code> - A descriptive name for the buffer.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">device</code></strong>: <code class="language-plaintext highlighter-rouge">GPUDevice</code> - <strong>(Required)</strong> The WebGPU device used to create the buffer.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">datatype</code></strong>: <code class="language-plaintext highlighter-rouge">string</code> - <strong>(Required)</strong> The data type of elements in the buffer (e.g., <code class="language-plaintext highlighter-rouge">'f32'</code>, <code class="language-plaintext highlighter-rouge">'u32'</code>, <code class="language-plaintext highlighter-rouge">'i32'</code>).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">size</code></strong>: <code class="language-plaintext highlighter-rouge">number</code> - The buffer’s total size in bytes. You must specify either <strong><code class="language-plaintext highlighter-rouge">size</code></strong> or <strong><code class="language-plaintext highlighter-rouge">length</code></strong>, but not both.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">length</code></strong>: <code class="language-plaintext highlighter-rouge">number</code> - The number of elements in the buffer.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">usage</code></strong>: <code class="language-plaintext highlighter-rouge">GPUBufferUsageFlags</code> - Specifies how the GPU buffer will be used. It defaults to <code class="language-plaintext highlighter-rouge">GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST</code>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">buffer</code></strong>: <code class="language-plaintext highlighter-rouge">GPUBuffer</code> or <code class="language-plaintext highlighter-rouge">GPUBufferBinding</code> - An existing buffer to wrap. If you provide this, <strong><code class="language-plaintext highlighter-rouge">createGPUBuffer</code></strong> should be <code class="language-plaintext highlighter-rouge">false</code>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">createCPUBuffer</code></strong>: <code class="language-plaintext highlighter-rouge">boolean</code> - If <code class="language-plaintext highlighter-rouge">true</code>, a CPU-side <code class="language-plaintext highlighter-rouge">TypedArray</code> is created.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">initializeCPUBuffer</code></strong>: <code class="language-plaintext highlighter-rouge">string</code> - A keyword specifying how to fill the CPU buffer with initial data.
    <ul>
      <li>For floats (<code class="language-plaintext highlighter-rouge">'f32'</code>): <code class="language-plaintext highlighter-rouge">'randomizeMinusOneToOne'</code>, <code class="language-plaintext highlighter-rouge">'randomizeAbsUnder1024'</code>, <code class="language-plaintext highlighter-rouge">'fisher-yates'</code>.</li>
      <li>For integers (<code class="language-plaintext highlighter-rouge">'u32'</code>, <code class="language-plaintext highlighter-rouge">'i32'</code>, <code class="language-plaintext highlighter-rouge">'u64'</code>): <code class="language-plaintext highlighter-rouge">'xor-beef'</code>, <code class="language-plaintext highlighter-rouge">'randomizeAbsUnder1024'</code>, <code class="language-plaintext highlighter-rouge">'constant'</code>, <code class="language-plaintext highlighter-rouge">'bitreverse'</code>, <code class="language-plaintext highlighter-rouge">'randomBytes'</code>, <code class="language-plaintext highlighter-rouge">'fisher-yates'</code>.</li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">storeCPUBackup</code></strong>: <code class="language-plaintext highlighter-rouge">boolean</code> - If <code class="language-plaintext highlighter-rouge">true</code>, a backup of the initialized CPU buffer is saved for later (this is useful if the primitive overwrites the buffer contents but we still need the original contents, for instance if we are validating the output).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">createGPUBuffer</code></strong>: <code class="language-plaintext highlighter-rouge">boolean</code> - If <code class="language-plaintext highlighter-rouge">true</code>, the corresponding <code class="language-plaintext highlighter-rouge">GPUBuffer</code> is created on the GPU.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">initializeGPUBuffer</code></strong>: <code class="language-plaintext highlighter-rouge">boolean</code> - If <code class="language-plaintext highlighter-rouge">true</code>, data from the CPU buffer is immediately copied to the GPU buffer. Requires <code class="language-plaintext highlighter-rouge">createCPUBuffer</code> to be <code class="language-plaintext highlighter-rouge">true</code>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">createMappableGPUBuffer</code></strong>: <code class="language-plaintext highlighter-rouge">boolean</code> - If <code class="language-plaintext highlighter-rouge">true</code>, a secondary, mappable GPU buffer is also created to help read data back from the GPU.</li>
</ul>

<hr />

<h2 id="methods">Methods</h2>

<h3 id="createcpubufferargs"><code class="language-plaintext highlighter-rouge">createCPUBuffer(args)</code></h3>

<p>Creates and optionally initializes the CPU-side <code class="language-plaintext highlighter-rouge">TypedArray</code> buffer. You can call this after construction if the buffer wasn’t created in the constructor.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">args</code></strong>: <code class="language-plaintext highlighter-rouge">object</code> - An optional object to override the instance’s <strong><code class="language-plaintext highlighter-rouge">length</code></strong> and <strong><code class="language-plaintext highlighter-rouge">datatype</code></strong> or provide initialization options.</li>
</ul>

<h3 id="creategpubufferargs"><code class="language-plaintext highlighter-rouge">createGPUBuffer(args)</code></h3>

<p>Creates the <code class="language-plaintext highlighter-rouge">GPUBuffer</code> on the device. You can call this after construction if the GPU buffer wasn’t created in the constructor.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">args</code></strong>: <code class="language-plaintext highlighter-rouge">object</code> - An optional object to override the instance’s <strong><code class="language-plaintext highlighter-rouge">device</code></strong>, <strong><code class="language-plaintext highlighter-rouge">size</code></strong>, <strong><code class="language-plaintext highlighter-rouge">datatype</code></strong>, or <strong><code class="language-plaintext highlighter-rouge">usage</code></strong>.</li>
</ul>

<h3 id="createmappablegpubuffersize"><code class="language-plaintext highlighter-rouge">createMappableGPUBuffer(size)</code></h3>

<p>Creates a separate GPU buffer that can be mapped by the CPU. This buffer is used as a temporary staging area for transferring data from the main GPU buffer back to the CPU.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">size</code></strong>: <code class="language-plaintext highlighter-rouge">number</code> - The size in bytes for the mappable buffer.</li>
</ul>

<h3 id="copycputogpu"><code class="language-plaintext highlighter-rouge">copyCPUToGPU()</code></h3>

<p>Uploads data from the CPU-side buffer (<code class="language-plaintext highlighter-rouge">cpuBuffer</code>) to the main GPU buffer.</p>

<h3 id="async-copygputocpu"><code class="language-plaintext highlighter-rouge">async copyGPUToCPU()</code></h3>

<p>Asynchronously copies data from the GPU buffer back to the CPU-side buffer. It works by copying the data to a temporary mappable buffer, reading it back to the CPU, and updating the <code class="language-plaintext highlighter-rouge">cpuBuffer</code> property.</p>

<h3 id="copycpubackuptocpu"><code class="language-plaintext highlighter-rouge">copyCPUBackupToCPU()</code></h3>

<p>Restores the <code class="language-plaintext highlighter-rouge">cpuBuffer</code> from the backup that was created during initialization.</p>

<h3 id="destroy"><code class="language-plaintext highlighter-rouge">destroy()</code></h3>

<p>Destroys the associated GPU buffers to free up GPU memory.</p>

<hr />

<h2 id="properties-getters--setters">Properties (Getters &amp; Setters)</h2>

<h3 id="buffer"><code class="language-plaintext highlighter-rouge">buffer</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the GPU buffer as a <code class="language-plaintext highlighter-rouge">GPUBufferBinding</code> object (e.g., <code class="language-plaintext highlighter-rouge">{ buffer: GPUBuffer }</code>).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">set</code></strong>: Sets the internal GPU buffer. Accepts a raw <code class="language-plaintext highlighter-rouge">GPUBuffer</code> or a <code class="language-plaintext highlighter-rouge">GPUBufferBinding</code> object.</li>
</ul>

<h3 id="cpubuffer"><code class="language-plaintext highlighter-rouge">cpuBuffer</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the CPU-side <code class="language-plaintext highlighter-rouge">TypedArray</code> (e.g., <code class="language-plaintext highlighter-rouge">Float32Array</code>, <code class="language-plaintext highlighter-rouge">Uint32Array</code>).</li>
</ul>

<h3 id="cpubufferbackup"><code class="language-plaintext highlighter-rouge">cpuBufferBackup</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the backup <code class="language-plaintext highlighter-rouge">TypedArray</code> if one was created.</li>
</ul>

<h3 id="size"><code class="language-plaintext highlighter-rouge">size</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the size of the buffer in <strong>bytes</strong>.</li>
</ul>

<h3 id="length"><code class="language-plaintext highlighter-rouge">length</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the number of <strong>elements</strong> in the buffer.</li>
</ul>

<h3 id="device"><code class="language-plaintext highlighter-rouge">device</code></h3>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">get</code></strong>: Returns the associated <code class="language-plaintext highlighter-rouge">GPUDevice</code>.</li>
</ul>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Explore the Buffer class that encapsulates data spanning CPU and GPU with consistent typed arrays and GPUBuffers.]]></summary></entry><entry><title type="html">Gridwise’s Binary Operator Class</title><link href="http://localhost:4000/gridwise/docs/2025/09/16/binop/" rel="alternate" type="text/html" title="Gridwise’s Binary Operator Class" /><published>2025-09-16T00:00:00-04:00</published><updated>2025-09-16T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/09/16/binop</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/09/16/binop/"><![CDATA[<p>Gridwise’s binary operator class is called <code class="language-plaintext highlighter-rouge">binop</code>. This class represents a <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a>, which has as its constituent parts a binary operation, a datatype for the data on which the operator is applied, and an identity element. (If we call the identity element <code class="language-plaintext highlighter-rouge">I</code> and the operator <code class="language-plaintext highlighter-rouge">op</code>, then <code class="language-plaintext highlighter-rouge">x = I op x</code>. For instance, addition’s identity is zero, and multiplication’s is one.) In Gridwise, we package these elements into an instance of a JS class, <code class="language-plaintext highlighter-rouge">BinOp</code>. This class then defines a number of objects that are used in WGSL code generation and CPU correctness checking.</p>

<p><code class="language-plaintext highlighter-rouge">BinOp</code> is implemented in the source file binop.md. We specialize <code class="language-plaintext highlighter-rouge">BinOp</code> to particular operations (e.g., <code class="language-plaintext highlighter-rouge">Add</code>) and then further specialize it with a datatype. Many Gridwise primitives require a <code class="language-plaintext highlighter-rouge">BinOp</code> argument and the common use will be something like:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">myPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">gridwisePrimitive</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">binop</span><span class="p">:</span> <span class="nx">BinOpAddU32</span><span class="p">,</span>   <span class="c1">// predefined in binop.js</span>
  <span class="p">...</span>
</code></pre></div></div>

<p>or</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">datatype</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">myPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">gridwisePrimitive</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">binop</span><span class="p">:</span> <span class="k">new</span> <span class="nx">BinOpAdd</span><span class="p">({</span> <span class="nx">datatype</span> <span class="p">}),</span>  <span class="c1">// instantiate on the fly, e.g.,</span>
                                      <span class="c1">// if datatype is generated at runtime</span>
  <span class="p">...</span>
</code></pre></div></div>

<h2 id="what-does-a-binop-provide--what-must-a-binop-define">What does a BinOp provide / what must a BinOp define?</h2>

<p>We want to write primitives that work for any monoid. Other languages have more structured ways to write such code, but WGSL development in JavaScript commonly uses string-pasting to construct runtime-generated kernels. A <code class="language-plaintext highlighter-rouge">BinOp</code> provides all the text and member functions that are specific to the particular monoid we are using. These are:</p>

<ul>
  <li>An identity element <code class="language-plaintext highlighter-rouge">identity</code>. For addition, this is 0 (independent of datatype). For multiplication, it is 1; for minimum, the largest representable value for that datatype; for maximum, the smallest representable value. Example: <code class="language-plaintext highlighter-rouge">this.identity = 0;</code></li>
  <li>A CPU-side function <code class="language-plaintext highlighter-rouge">op</code>. This JavaScript function takes two arguments <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> and returns <code class="language-plaintext highlighter-rouge">a op b</code>. Because JavaScript’s internal datatypes are limited, this sometimes requires judicious use of JavaScript typed arrays. (We are happy to take suggestions on how we can do this more efficiently.) Example: <code class="language-plaintext highlighter-rouge">this.op = (a, b) =&gt; a + b;</code></li>
  <li>A GPU-side function declaration <code class="language-plaintext highlighter-rouge">wgslop</code>. This must define a WGSL function named <code class="language-plaintext highlighter-rouge">binop</code>. Like <code class="language-plaintext highlighter-rouge">op</code>, this function takes two arguments <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> and returns <code class="language-plaintext highlighter-rouge">a op b</code>. It can use string interpolation as appropriate and will probably have to use a datatype. Example: <code class="language-plaintext highlighter-rouge">this.wgslfn = fn binop(a : ${this.datatype}, b : ${this.datatype}) -&gt; ${this.datatype} {return a+b;};</code></li>
  <li>Four optional WGSL function names. These are “optional” in the sense that they are not a core part of <code class="language-plaintext highlighter-rouge">BinOp</code>, so most primitives will probably work if they are not specified. These are:
    <ul>
      <li>An atomic function <code class="language-plaintext highlighter-rouge">wgslatomic</code>. This should be a string that is a function name. This names the WGSL atomic function that is the atomic variant of <code class="language-plaintext highlighter-rouge">wgslop</code>. Any of <a href="https://www.w3.org/TR/WGSL/#atomic-rmw">these functions</a> are appropriate, but note that (at the time of writing) WGSL atomics are only available for <code class="language-plaintext highlighter-rouge">i32</code> and <code class="language-plaintext highlighter-rouge">u32</code> datatypes. Example: <code class="language-plaintext highlighter-rouge">this.wgslatomic = "atomicAdd";</code></li>
      <li>Three subgroup functions. Note these functions apply to only a subset of operations and datatypes. Supporting anything outside of this subset requires <a href="subgroup-strategy.html">emulation</a>.
        <ul>
          <li><code class="language-plaintext highlighter-rouge">subgroupReduceOp</code>, which reduces the values in a subgroup using this operation. At the time of writing, supported WGSL functions of this type are <code class="language-plaintext highlighter-rouge">subgroup{Add,And,Max,Min,Mul,Or,Xor}</code>. Example: <code class="language-plaintext highlighter-rouge">this.subgroupReduceOp = "subgroupAdd";</code></li>
          <li><code class="language-plaintext highlighter-rouge">subgroupInclusiveScanOp</code>, which computes an inclusive scan of the values in a subgroup using this operation. At the time of writing, supported WGSL functions of this type are <code class="language-plaintext highlighter-rouge">subgroupInclusive{Add,Mul}</code>. Example: <code class="language-plaintext highlighter-rouge">this.subgroupInclusiveScanOp = "subgroupInclusiveAdd";</code></li>
          <li><code class="language-plaintext highlighter-rouge">subgroupExclusiveScanOp</code>, which computes an exclusive scan of the values in a subgroup using this operation. At the time of writing, supported WGSL functions of this type are <code class="language-plaintext highlighter-rouge">subgroupExclusive{Add,Mul}</code>. Example: <code class="language-plaintext highlighter-rouge">this.subgroupExclusiveScanOp = "subgroupExclusiveAdd";</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Below is an example implementation, <code class="language-plaintext highlighter-rouge">BinOpAdd</code>, which takes an argument of <code class="language-plaintext highlighter-rouge">{ datatype = "..." }</code> that is used to specialize it.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">export</span> <span class="kd">class</span> <span class="nx">BinOpAdd</span> <span class="kd">extends</span> <span class="nx">BinOp</span> <span class="p">{</span>
  <span class="kd">constructor</span><span class="p">(</span><span class="nx">args</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">super</span><span class="p">(</span><span class="nx">args</span><span class="p">);</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">identity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nx">args</span><span class="p">.</span><span class="nx">datatype</span> <span class="o">==</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">)</span> <span class="p">{</span>
      <span class="kd">const</span> <span class="nx">f32array</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">Float32Array</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">op</span> <span class="o">=</span> <span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="nx">f32array</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nx">a</span><span class="p">;</span>
        <span class="nx">f32array</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nx">b</span><span class="p">;</span>
        <span class="nx">f32array</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nx">f32array</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nx">f32array</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
        <span class="k">return</span> <span class="nx">f32array</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
      <span class="p">};</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">op</span> <span class="o">=</span> <span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="nx">a</span> <span class="o">+</span> <span class="nx">b</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">switch</span> <span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">datatype</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">case</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">:</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="k">case</span> <span class="dl">"</span><span class="s2">i32</span><span class="dl">"</span><span class="p">:</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="k">case</span> <span class="dl">"</span><span class="s2">u32</span><span class="dl">"</span><span class="p">:</span> <span class="c1">// fall-through OK</span>
      <span class="k">default</span><span class="p">:</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">wgslatomic</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">atomicAdd</span><span class="dl">"</span><span class="p">;</span> <span class="c1">// u32 only</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">wgslfn</span> <span class="o">=</span> <span class="s2">`fn binop(a : </span><span class="p">${</span><span class="k">this</span><span class="p">.</span><span class="nx">datatype</span><span class="p">}</span><span class="s2">, b : </span><span class="p">${</span><span class="k">this</span><span class="p">.</span><span class="nx">datatype</span><span class="p">}</span><span class="s2">) -&gt; </span><span class="p">${</span><span class="k">this</span><span class="p">.</span><span class="nx">datatype</span><span class="p">}</span><span class="s2"> {return a+b;}`</span><span class="p">;</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">subgroupReduceOp</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">subgroupAdd</span><span class="dl">"</span><span class="p">;</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">subgroupInclusiveScanOp</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">subgroupInclusiveAdd</span><span class="dl">"</span><span class="p">;</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">subgroupExclusiveScanOp</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">subgroupExclusiveAdd</span><span class="dl">"</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Learn about Gridwise's BinOp class that represents monoids for binary operations and WGSL code generation.]]></summary></entry><entry><title type="html">Gridwise Sort</title><link href="http://localhost:4000/gridwise/docs/2025/09/16/sort/" rel="alternate" type="text/html" title="Gridwise Sort" /><published>2025-09-16T00:00:00-04:00</published><updated>2025-09-16T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/09/16/sort</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/09/16/sort/"><![CDATA[<p>The dominant approach to GPU sorting is a <a href="https://en.wikipedia.org/wiki/Radix_sort">radix sort</a> over input keys. In general, radix sorts deliver high performance on GPUs because they require <em>O(n)</em> work for inputs of <em>n</em> elements, because their constituent memory accesses are generally fairly coalesced and thus deliver good memory performance, and because the underlying compute primitives that compose to make the sort are good matches for GPUs.</p>

<p>The specific sort architecture we choose is <a href="https://research.nvidia.com/publication/2022-06_onesweep-faster-least-significant-digit-radix-sort-gpus">OneSweep</a>, developed by Andrey Adinets and Duane Merrill of NVIDIA. Internally, OneSweep uses a chained scan, as does our implementation. The challenges we outlined in our <a href="scan-and-reduce.html#decoupled-lookback-and-forward-progress-guarantees">scan description</a> with respect to forward-progress guarantees are the same. Our sort implementation employs both lookback and fallback to ensure that it will work on GPUs that lack forward-progress guarantees.</p>

<h2 id="our-sort-implementation">Our Sort Implementation</h2>

<p>At its heart, radix sort computes a permutation of its input values and then performs the permutation. Computing the entire permutation would be intractable (the size of the intermediate data structures would be enormous), so typically a radix sort makes several passes over the input, each time computing a permutation for a subset of input bits (this subset is called a “digit”). OneSweep begins with the least significant bits, as do we. Our implementation considers 8 bits per pass, meaning each digit can take on 2^8 = 256 possible values. We thus require 4 passes to sort 32-bit keys. On each pass, we classify the key into one of 256 “buckets” based on its digit value. The permutation we want to compute will always place keys with lower digit values before keys with higher digit values.</p>

<p>As with scan, we divide the input into equal-sized “tiles” and assign one workgroup to each tile.</p>

<p>Computing this permutation means computing a “destination address” for each key—to where in the output will this key be written? That address is the sum of:</p>

<ol>
  <li>The number of keys that fall into a bucket before my bucket</li>
  <li>The number of keys that are in my bucket and are processed in a previous tile</li>
  <li>The number of keys that are in my bucket and are processed earlier than
my key within my tile</li>
</ol>

<p>We compute (1) by constructing a global histogram of all bucket sizes (kernel: <code class="language-plaintext highlighter-rouge">global_hist</code>, which constructs a separate histogram for each digit) and then running exclusive-sum-scan on these histograms (kernel: <code class="language-plaintext highlighter-rouge">onesweep_scan</code>).</p>

<p>We compute (2) by first computing the number of keys per bucket within my histogram and then using a chained sum scan to retrieve the sum of the sizes of the previous workgroup’s buckets (kernel: <code class="language-plaintext highlighter-rouge">onesweep_pass</code>). We add in (1) at the start of this chained scan, so we actually chained-scan (1) + (2). The chained scan requires lookback to look at the results of this scan, and if the hardware does not offer forward-progress guarantees, the chained scan also requires fallback to redundantly compute this value. We compute (3) in <code class="language-plaintext highlighter-rouge">onesweep_pass</code> as well, but it is workgroup-local only; it does not participate in the chained-scan.</p>

<p>Given this computed address per key, we could directly scatter each key to its location in global memory. However, to improve memory coalescing, we first write keys into workgroup memory and scatter from there. This puts neighboring keys next to each other in workgroup memory and significantly improves the throughput of the global scatter.</p>

<p>Note that the chained scan in onesweep is a chained scan over an entire 256-entry histogram. Lookback on such a large data structure is more complicated than lookback on a single data value, as we see in <a href="scan-and-reduce.html">our scan implementation</a>, because we use an entire workgroup to look back. The additional complexity is that <em>any</em> thread in the lookback may fail to find a ready value, and if this is the case, the entire workgroup must drop into fallback. Thus we have to keep track of both per-thread lookback success as well as per-subgroup lookback success, and only determine lookback is successful if all subgroups report success.</p>

<p>Radix sort implementations (including ours) typically use a ping-pong pair of arrays: on each pass, one array is the input and one array is the output, and on each pass, their roles switch. Because we are sorting 32- or 64-bit keys at 8 bits per pass, this means the input will be overwritten by the output and the primitive’s output will be produced in the same buffer as its original input. Overwriting the input is not ideal behavior but is probably preferable to approaches that hide it from the user (by, say, preemptively copying the input into a temporary buffer and copying the temporary input and output at the end of the computation).</p>

<h2 id="configuring-and-calling-gridwise-sort">Configuring and Calling Gridwise Sort</h2>

<h3 id="defining-the-primitive">Defining the primitive</h3>

<p>Declare the scan or reduce primitive as an instance of the <code class="language-plaintext highlighter-rouge">OneSweepSort</code> class.  An example scan declaration:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">datatype</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">u32</span><span class="dl">"</span><span class="p">;</span> <span class="c1">// or "i32" or "f32"</span>
<span class="kd">const</span> <span class="nx">oneSweepSortPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">OneSweepSort</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="nx">datatype</span><span class="p">,</span> <span class="c1">// use the "datatype" string defined above</span>
  <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">keysonly</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">direction</span><span class="p">:</span> <span class="dl">"</span><span class="s2">ascending</span><span class="dl">"</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<p>Gridwise OneSweep supports all combinations of:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">datatype</code>: <code class="language-plaintext highlighter-rouge">u32</code>, <code class="language-plaintext highlighter-rouge">i32</code>, <code class="language-plaintext highlighter-rouge">f32</code>, <code class="language-plaintext highlighter-rouge">u64</code>. Internally, OneSweep converts non-unsigned-int keys into unsigned-int keys that respect the original order, sorts as if the keys were unsigned ints, and then reverses the conversion when writing the keys into the output.</li>
  <li><code class="language-plaintext highlighter-rouge">type</code>: <code class="language-plaintext highlighter-rouge">keysonly</code>, <code class="language-plaintext highlighter-rouge">keyvalue</code>. A key-value sort has an array of keys and also an array of values where each value is associated with its corresponding key in the keys array. Default: <code class="language-plaintext highlighter-rouge">keysonly</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">direction</code>: <code class="language-plaintext highlighter-rouge">ascending</code>, <code class="language-plaintext highlighter-rouge">descending</code>. The default is <code class="language-plaintext highlighter-rouge">ascending</code> (sort low to high), but we support sorting in the other direction as well.</li>
</ul>

<h3 id="configuring-the-primitive">Configuring the primitive</h3>

<p>Once the primitive is <em>defined</em>, it must then be <em>configured</em>. The primitive knows that it requires an input/output and temporary buffer, labeled <code class="language-plaintext highlighter-rouge">keysInOut</code> and <code class="language-plaintext highlighter-rouge">keysTemp</code>. (We use our <a href="buffer.html"><code class="language-plaintext highlighter-rouge">Buffer</code> class</a> for this.) If we are doing a key-value sort, we also require <code class="language-plaintext highlighter-rouge">payloadInOut</code> and <code class="language-plaintext highlighter-rouge">payloadTemp</code> buffers, which store the values.) We configure the primitive by registering data buffers with the primitive. This can be done either with a <code class="language-plaintext highlighter-rouge">primitive.registerBuffer()</code> call or as an argument to the <code class="language-plaintext highlighter-rouge">execute</code> call. (The former is preferred if we need to register the buffer(s) once and then call <code class="language-plaintext highlighter-rouge">execute</code> many times.)</p>

<p>To register a buffer, simply call <code class="language-plaintext highlighter-rouge">primitive.registerBuffer(buffer)</code>, where <code class="language-plaintext highlighter-rouge">buffer.label</code> is one of the buffers above. The below code creates a <code class="language-plaintext highlighter-rouge">Buffer</code> then registers it.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">inputLength</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">20</span><span class="p">;</span>
<span class="nx">testKeysBuffer</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Buffer</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">datatype</span><span class="p">:</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">length</span><span class="p">:</span> <span class="nx">inputLength</span><span class="p">,</span>
  <span class="na">label</span><span class="p">:</span> <span class="dl">"</span><span class="s2">keysInOut</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">createCPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeCPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* fill with default data */</span><span class="p">,</span>
  <span class="na">storeCPUBackup</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span> <span class="cm">/* because readback will overwrite the CPU data */</span>
  <span class="na">createGPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeGPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* with CPU data */</span><span class="p">,</span>
  <span class="na">createMappableGPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span> <span class="cm">/* we read this back to test correctness */</span>
<span class="p">});</span>
<span class="nx">oneSweepSortPrimitive</span><span class="p">.</span><span class="nx">registerBuffer</span><span class="p">(</span><span class="nx">testKeysBuffer</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="calling-scan-or-reduce">Calling scan or reduce</h3>

<p>Once the primitive is defined and configured, simply call its <code class="language-plaintext highlighter-rouge">execute()</code> method.</p>

<p>If you have not yet registered buffers, you can specify them in the argument object as <code class="language-plaintext highlighter-rouge">keysInOut</code>, <code class="language-plaintext highlighter-rouge">keysTemp</code>, etc.</p>

<p>Other possible arguments (which are timing-specific and thus which you are unlikely to use unless you are benchmarking) are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">trials</code> with an integer argument. This will run the kernel(s) that number of times. Default: 1.</li>
  <li><code class="language-plaintext highlighter-rouge">enableGPUTiming</code> with either true or false. If true, please ensure that the device has a set of required features that include <code class="language-plaintext highlighter-rouge">timestamp-query</code>. Default: false.</li>
  <li><code class="language-plaintext highlighter-rouge">enableCPUTiming</code> with either true or false. Default: false.</li>
</ul>

<p>Note that <code class="language-plaintext highlighter-rouge">execute()</code> is declared <code class="language-plaintext highlighter-rouge">async</code>.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">await</span> <span class="nx">oneSweepSortPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">();</span>
<span class="c1">// or, if we want to specify buffers only when execute is called</span>
<span class="k">await</span> <span class="nx">oneSweepSortPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">keysInOut</span><span class="p">:</span> <span class="nx">testKeysBuffer</span><span class="p">,</span>
  <span class="na">keysTemp</span><span class="p">:</span> <span class="nx">testKeysTempBuffer</span><span class="p">,</span>
<span class="p">});</span>
<span class="c1">// or (maybe if you're benchmarking)</span>
<span class="k">await</span> <span class="nx">oneSweepSortPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">trials</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="na">enableGPUTiming</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="na">enableCPUTiming</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<h2 id="usage-and-performance-notes">Usage and performance notes</h2>

<p>The number of items to sort must be no greater than 2^30. (CUB does the same thing.) We use the two most-significant bits as status bits. It would take a large engineering effort to remove this limitation.</p>

<p>Just as with scan, input lengths <em>must be</em> a multiple of 4. Pad the end of your input array with enough largest-key-value elements to make this work. (This is because internally, we use <code class="language-plaintext highlighter-rouge">vec4</code>s for computation.)</p>

<p>During its development, sort had extensive performance testing and the defaults are fairly stable across different GPUs. We sort 8 bits per pass and this particular implementation has never been tested with a different number of bits per pass. This could be remedied with engineering effort.</p>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Learn about Gridwise's GPU radix sort implementation using OneSweep architecture for high-performance sorting.]]></summary></entry><entry><title type="html">Gridwise WebGPU @builtins Strategy</title><link href="http://localhost:4000/gridwise/docs/2025/08/22/builtins-strategy/" rel="alternate" type="text/html" title="Gridwise WebGPU @builtins Strategy" /><published>2025-08-22T00:00:00-04:00</published><updated>2025-08-22T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/08/22/builtins-strategy</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/08/22/builtins-strategy/"><![CDATA[]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Learn about Gridwise's strategy for handling WebGPU @builtins and shader optimization techniques.]]></summary></entry><entry><title type="html">Gridwise WebGPU Subgroup Emulation Strategy</title><link href="http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/" rel="alternate" type="text/html" title="Gridwise WebGPU Subgroup Emulation Strategy" /><published>2025-08-18T00:00:00-04:00</published><updated>2025-08-18T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/"><![CDATA[<p>WGSL’s <a href="https://gpuweb.github.io/gpuweb/wgsl/#subgroup-builtin-functions">subgroup built-in functions</a> have the potential to significantly improve performance on subgroup-capable hardware. A <a href="https://web3dsurvey.com/webgpu">large (and growing) fraction of WebGPU devices</a> support subgroups. However, writing high-performance code that supports both using subgroups when available <em>and</em> falls back to code with no subgroups is a challenge. This document describes my experience attempting to do exactly that.</p>

<p>In the below discussion, we use the term “hw” to indicate “the development experience that targets hardware-supported subgroups” and “emu” for the development experience that targets non-hardware-supported subgroups, which are not supported by WGSL and thus must be emulated”.</p>

<h2 id="goals-of-this-effort">Goals of this effort</h2>

<p>In an ideal world, this effort would have resulted in the following outcomes:</p>

<ul>
  <li>For users of primitives:
    <ul>
      <li>No code changes. The same code runs on both subgroup-capable (hw) and non-subgroup-capable (emu) hardware</li>
      <li>However, my effort did not prioritize performance for emu hardware</li>
      <li>To prioritize performance here, it is likely that we’d need separate primitive formulations for hw/emu scenarios</li>
    </ul>
  </li>
  <li>For developers of primitives:
    <ul>
      <li>Minimal additional complexity. This was not entirely achieved.</li>
    </ul>
  </li>
</ul>

<p>The checked-in code does not work out of the box for emu. It would not be excessively difficult to make it work, but it would take several hours of grungy effort. I priorized hw development, not emu development, during our scan implementation; scan is already quite complicated and keeping it working for both during active development was just not a priority.</p>

<h2 id="initial-goal-subgroupshuffle">Initial goal: subgroupShuffle</h2>

<p>Let’s begin by making one call, <a href="https://www.w3.org/TR/WGSL/#subgroupshuffle-builtin"><code class="language-plaintext highlighter-rouge">subgroupShuffle</code></a>, work in both hw and emu contexts. This call looks like:</p>

<pre><code class="language-wgsl">y = subgroupShuffle(x, id);
</code></pre>

<p>The first roadblock is that <code class="language-plaintext highlighter-rouge">subgroupShuffle</code> is not defined as an emu function. Fortunately (and intelligently), WGSL allows the programmer to directly override it (“shadow”) with a user-specified function. So let’s do that (for the emu context only). If we lack subgroup hardware, we have to communicate shuffled values through workgroup memory, so we have to declare a region of workgroup memory with one element per thread. Here, <code class="language-plaintext highlighter-rouge">source</code> is a thread index within the subgroup, and <code class="language-plaintext highlighter-rouge">sgid</code> is the <code class="language-plaintext highlighter-rouge">@builtin(subgroup_invocation_id)</code>. The code is straightforward:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_sw_subgroups: array&lt;u32, 256&gt;;
fn subgroupShuffle(x: u32, source: u32) -&gt; u32 {
  wg_sw_subgroups[sgid] = x;
  workgroupBarrier();
  return wg_sw_subgroups[source];
}
</code></pre>

<p>Great! We’re done!</p>

<p>Well, not so much. There are many challenges ahead of us.</p>

<h3 id="challenge-the-builtin-sgid">Challenge: the @builtin sgid</h3>

<p>Our first challenge is using <code class="language-plaintext highlighter-rouge">@builtin(subgroup_invocation_id) sgid</code>. In emu, this <code class="language-plaintext highlighter-rouge">@builtin</code> is not defined. We can pass it in as an argument, however.</p>

<p>Thus one possible solution is to define <code class="language-plaintext highlighter-rouge">fn subgroupShuffleWrapper(x, source, sgid)</code> and then use <code class="language-plaintext highlighter-rouge">subgroupShuffleWrapper</code> everywhere. We began our development using this strategy, but it is undesirable; it’s not reasonable to ask every possible developer within this library to use a set of different functions with different APIs than those in the spec, and it significantly complicated development. We needed a better way, which we address as part of the next challenge.</p>

<h3 id="challenge-supporting-both-hw-and-emu-with-minimal-impact-on-the-programmer">Challenge: supporting both hw and emu with minimal impact on the programmer</h3>

<p>Our second challenge is ensuring that our <code class="language-plaintext highlighter-rouge">fn subgroupShuffle</code> definition is only visible when the kernel is compiled in emu, but not in hw. How can we do this?</p>

<p>First, the WebGPU call <code class="language-plaintext highlighter-rouge">device.features.has("subgroups")</code> tells us if subgroups are supported. We can use the result of this call to declare one of two sets of functions: one that assumes subgroups are available (hw) and one that does not (emu). In our implementation, this set of functions is called <code class="language-plaintext highlighter-rouge">fnDeclarations</code>. Our syntax is not important here; what is important is what happens in hw and what happens in emu.</p>

<p>At the top of the kernel, we require <code class="language-plaintext highlighter-rouge">${this.fnDeclarations.enableSubgroupsIfAppropriate}</code>. If we are hw, this emits <code class="language-plaintext highlighter-rouge">enable subgroups;</code>; if we are emu, this emits nothing.</p>

<p>With our next declaration, we partially solve the problem we identified above, where the subgroup size and subgroup id builtins are available in hw but not in emu. If the kernel is using any subgroup calls, we require <code class="language-plaintext highlighter-rouge">${this.fnDeclarations.subgroupEmulation}</code>. In hw, this emits nothing. In emu, this declares workgroup memory (for performing the subgroup operations) and subgroup variables (subgroup size and subgroup id), all at module scope:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_sw_subgroups: array&lt;${env.datatype}, ${env.workgroupSize}&gt;;
const sgsz: u32 = ${env.workgroupSize};
var&lt;private&gt; sgid: u32;
</code></pre>

<p>However, it does not actually assign values to <code class="language-plaintext highlighter-rouge">sgsz</code> and <code class="language-plaintext highlighter-rouge">sgid</code>.</p>

<p>Next, for each subgroup call we want to make, we “declare” the call. For subgroup shuffle, in hw, we emit nothing, because <code class="language-plaintext highlighter-rouge">subgroupShuffle</code> is builtin. In emu (note we use the <code class="language-plaintext highlighter-rouge">sgid</code> variable we declared at module scope above):</p>

<pre><code class="language-wgsl">fn subgroupShuffle(x: u32, source: u32) -&gt; u32 {
  /* subgroup emulation must pass through wg_sw_subgroups */
  /* write my value to workgroup memory */
  wg_sw_subgroups[sgid] = bitcast&lt;${env.datatype}&gt;(x);
  workgroupBarrier();
  var shuffled: u32 = bitcast&lt;u32&gt;(wg_sw_subgroups[source]);
  workgroupBarrier();
  return shuffled;
}
</code></pre>

<p>In hw, each supported subgroup call emits nothing, but we also define other useful functions that are not already defined and emit different implementations for hw and emu. (Example: WGSL supports both inclusive (<code class="language-plaintext highlighter-rouge">subgroupInclusiveAdd</code>) and exclusive subgroup (<code class="language-plaintext highlighter-rouge">subgroupExclusiveAdd</code>) scans, but only if the scan operator is addition. Our function library has support for non-addition inclusive and exclusive subgroup scans for both hw and emu.)</p>

<p>Finally, we need to assign values to <code class="language-plaintext highlighter-rouge">sgsz</code> and <code class="language-plaintext highlighter-rouge">sgid</code> to functions wehre they are used. Here we use a declaration within each function, `      ${this.fnDeclarations.initializeSubgroupVars()}<code class="language-plaintext highlighter-rouge">. For hw, this does nothing. For emu, this emits </code>let sgsz: u32 = builtinsUniform.sgsz;\nlet sgid: u32 = builtinsNonuniform.sgid;`.</p>

<p>The burden on the programmer is to (1) declare necessary functions at the top of the module and (2) initialize subgroup variables at the top of each function that uses subgroups, but not to change kernel code. For a hypothetical module/kernel whose only subgroup operation is <code class="language-plaintext highlighter-rouge">subgroupShuffle</code>, that code looks like:</p>

<pre><code class="language-wgsl">${this.fnDeclarations.enableSubgroupsIfAppropriate} // must be first line of kernel
${this.fnDeclarations.subgroupEmulation}
${this.fnDeclarations.subgroupShuffle}

fn kernel() {
  ${this.fnDeclarations.initializeSubgroupVars()}
  // ...
}
</code></pre>

<h3 id="challenge-choosing-an-emulated-subgroup-size">Challenge: choosing an emulated subgroup size</h3>

<p>Finally, we will have to write each emu subgroup operation. Our third challenge is to choose a subgroup size to emulate.</p>

<p>First, we know that using hw subgroup operations will deliver better performance than emu, for several reasons.</p>

<ol>
  <li>Hardware-supported subgroup instructions will run faster than the sequences of instructions we need to emulate them</li>
  <li>Because emulated subgroups don’t run in lockstep, we will require more workgroup barriers to emulate subgroups
    <ul>
      <li>Workgroup barriers will have the largest impact in latency-sensitive and/or large-workgroup kernels</li>
    </ul>
  </li>
  <li>Emulated subgroup instructions need to run through workgroup memory, which is slower than registers</li>
  <li>Allocating additional workgroup memory (at least one word per thread of the workgroup) might decrease the number of subgroups that can fit on a processor, hurting occupancy</li>
</ol>

<p>Recall that WebGPU does not specify a subgroup size (in hw), although it does specify a minimum and maximum subgroup size. (In fact, some WebGPU-capable hardware may use different subgroup sizes across different kernels in the same application.) WebGPU developers must thus write their code assuming any subgroup size between the minimum and the maximum. Since our kernels already have to handle a range of subgroup sizes, we have some flexibility to choose a subgroup size in emu. We have 3 main choices:</p>

<ol>
  <li>Assume that very small subgroup sizes run in lockstep, and use those subgroup sizes. Then we can potentially avoid some barriers and gain some efficiency.
    <ul>
      <li>But: We can’t assume that. WebGPU does not report that information. (If it did, we could take advantage of it.)</li>
    </ul>
  </li>
  <li>Assume a comfortable subgroup size (e.g., 32), and add appropriate barriers.</li>
  <li>Since we’re going to have to put barriers everywhere anyway, assume subgroup size == workgroup size.</li>
</ol>

<p>Let’s take a step back and think about how subgroups are used. Consider a reduction across a workgroup (each thread has one item and the workgroup adds up all items). The typical pattern for a workgroup reduction leveraging subgroup support is to (a) use a subgroup reduction on each subgroup then (b) reduce across the results from each subgroup. This pattern is typical: parallelize across subgroups, then combine the results.</p>

<p>Now, if we choose alternatives 1 or 2, then it is highly likely that each workgroup will contain several subgroups. Many primitives will thus have two stages: per-subgroup, then per-workgroup. If we choose alternative 3 (subgroup size == workgroup size), then our algorithms may be simpler, because we don’t have to combine results from multiple subgroups within a workgroup. This also simplifies the code that emulates subgroups.</p>

<p>We do see one clear structural issue, though: some subgroup operations have a maximum size (e.g., <code class="language-plaintext highlighter-rouge">subgroupBallot</code> has a maximum subgroup size of 128, because it returns exactly 128 bits).</p>

<p>Nonetheless for simplicity, we currently choose to always emulate subgroups that are the size of the workgroup, recognizing that this is not a fully generalizable solution.</p>

<h2 id="summary">Summary</h2>

<p>On an Apple M3 with a high-performance scan kernel, the performance difference between hw and emu with the same kernel is ~2.5x.</p>

<p>An open question is whether it is better to write different <em>kernels</em> for hw and emu as opposed to what we did: writing different versions of subgroup functions and keeping the same kernel. The answer probably depends on the nature of the kernels. We did not explore the latter alternative at all.</p>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Discover Gridwise's approach to supporting WGSL subgroup functions while maintaining fallback compatibility for all devices.]]></summary></entry><entry><title type="html">Gridwise WebGPU Object Caching Strategy</title><link href="http://localhost:4000/gridwise/docs/2025/08/12/webgpu-object-caching-strategy/" rel="alternate" type="text/html" title="Gridwise WebGPU Object Caching Strategy" /><published>2025-08-12T00:00:00-04:00</published><updated>2025-08-12T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/08/12/webgpu-object-caching-strategy</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/08/12/webgpu-object-caching-strategy/"><![CDATA[<h2 id="gridwise-webgpu-object-caching-strategy">Gridwise WebGPU Object Caching Strategy</h2>

<p>This document outlines the caching strategy used for WebGPU objects within Gridwise. Creating WebGPU objects is not free and is potentially expensive. Caching created objects so that they can be reused potentially helps performance. The downsides of caching are that caching itself is not free and that the WebGPU back end may do its own caching. In Gridwise, caching is enabled by default but can be disabled (by instantiating a primitive with the argument <code class="language-plaintext highlighter-rouge">webgpucache = "disabled"</code>).</p>

<h3 id="cacheable-webgpu-objects">Cacheable WebGPU Objects</h3>

<p>The following WebGPU objects are currently cached by our library:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">GPUShaderModule</code></li>
  <li><code class="language-plaintext highlighter-rouge">GPUPipelineLayout</code></li>
  <li><code class="language-plaintext highlighter-rouge">GPUBindGroupLayout</code></li>
  <li><code class="language-plaintext highlighter-rouge">GPUComputePipeline</code></li>
</ul>

<p>Of these, <code class="language-plaintext highlighter-rouge">GPUShaderModule</code> is potentially independent of the <code class="language-plaintext highlighter-rouge">GPUDevice</code>, while the others are dependent on the specific <code class="language-plaintext highlighter-rouge">GPUDevice</code> instance.</p>

<h2 id="cache-implementation">Cache Implementation</h2>

<p>Every primitive shares a <code class="language-plaintext highlighter-rouge">\_\_deviceToWebGPUObjectCache</code>, which is a <code class="language-plaintext highlighter-rouge">WeakMap</code> that maps a <code class="language-plaintext highlighter-rouge">GPUDevice</code> to its corresponding cache. Each device’s cache contains several individual caches for different object types. These are regular <code class="language-plaintext highlighter-rouge">Map</code> objects that map a generated key to the WebGPU object.</p>

<p>The available caches are:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pipelineLayouts</code></li>
  <li><code class="language-plaintext highlighter-rouge">bindGroupLayouts</code></li>
  <li><code class="language-plaintext highlighter-rouge">computeModules</code></li>
  <li><code class="language-plaintext highlighter-rouge">computePipelines</code></li>
</ul>

<p>Each of these caches can be individually enabled or disabled when a primitive is created.</p>

<p>Here is a simplified code representation of the cache structure:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">export</span> <span class="kd">class</span> <span class="nx">BasePrimitive</span> <span class="p">{</span>
  <span class="kd">static</span> <span class="nx">__deviceToWebGPUObjectCache</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">WeakMap</span><span class="p">();</span>
  <span class="c1">// ... inside a method ...</span>
  <span class="nx">BasePrimitive</span><span class="p">.</span><span class="nx">__deviceToWebGPUObjectCache</span><span class="p">.</span><span class="kd">set</span><span class="p">(</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">device</span><span class="p">,</span>
    <span class="k">new</span> <span class="nx">WebGPUObjectCache</span><span class="p">()</span>
  <span class="p">);</span>
<span class="p">}</span>

<span class="kd">class</span> <span class="nx">WebGPUObjectCache</span> <span class="p">{</span>
  <span class="kd">constructor</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">caches</span> <span class="o">=</span> <span class="p">[</span>
      <span class="dl">"</span><span class="s2">pipelineLayouts</span><span class="dl">"</span><span class="p">,</span>
      <span class="dl">"</span><span class="s2">bindGroupLayouts</span><span class="dl">"</span><span class="p">,</span>
      <span class="dl">"</span><span class="s2">computeModules</span><span class="dl">"</span><span class="p">,</span>
      <span class="dl">"</span><span class="s2">computePipelines</span><span class="dl">"</span><span class="p">,</span>
    <span class="p">];</span>

    <span class="k">for</span> <span class="p">(</span><span class="kd">const</span> <span class="nx">cache</span> <span class="k">of</span> <span class="k">this</span><span class="p">.</span><span class="nx">caches</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">[</span><span class="nx">cache</span><span class="p">]</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">CountingMap</span><span class="p">({</span> <span class="c1">// wrapper over a Map</span>
        <span class="na">enabled</span><span class="p">:</span> <span class="k">this</span><span class="p">.</span><span class="nx">initiallyEnabled</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="nx">cache</span><span class="p">),</span>
      <span class="p">});</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="bind-group-caching">Bind Group Caching</h3>

<p>Bind groups are not cached. This decision was made because bind groups depend on <code class="language-plaintext highlighter-rouge">GPUBuffer</code> objects. Reliably creating a cache key from a
<code class="language-plaintext highlighter-rouge">GPUBuffer</code> is problematic due to its dynamic state.</p>

<h3 id="cache-key-generation">Cache Key Generation</h3>

<p>To use objects as keys in a Map, we need a consistent and unique representation. Since Maps use Same-Value-Zero equality, two different objects with the same properties will not be treated as the same key. To solve this, we <code class="language-plaintext highlighter-rouge">JSON.stringify</code> a simplified representation of the object to create a string-based cache key.</p>

<p>Here’s how keys are generated for different object types:</p>

<h4 id="pipeline-layout">Pipeline Layout</h4>

<p>The cache key for a <code class="language-plaintext highlighter-rouge">GPUPipelineLayout</code> is an array of strings representing the buffer types for that layout.</p>

<p>Example:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="dl">"</span><span class="s2">read-only-storage</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">storage</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">uniform</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">storage</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">storage</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">storage</span><span class="dl">"</span><span class="p">];</span>
</code></pre></div></div>

<h4 id="bind-group-layout">Bind Group Layout</h4>

<p>The cache key for a <code class="language-plaintext highlighter-rouge">GPUBindGroupLayout</code> is the set of entries for that layout.</p>

<p>Example:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span>
  <span class="p">{</span> <span class="na">binding</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="na">visibility</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="na">buffer</span><span class="p">:</span> <span class="p">{</span> <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">read-only-storage</span><span class="dl">"</span> <span class="p">}</span> <span class="p">},</span>
  <span class="p">{</span>
    <span class="na">binding</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="na">visibility</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="na">buffer</span><span class="p">:</span> <span class="p">{</span>
      <span class="cm">/*...*/</span>
    <span class="p">},</span>
  <span class="p">},</span>
  <span class="c1">// ... and so on for all entries</span>
<span class="p">];</span>
</code></pre></div></div>

<h4 id="compute-module">Compute Module</h4>

<p>The cache key for a <code class="language-plaintext highlighter-rouge">GPUShaderModule</code> (referred to as a compute module in the context of compute shaders) is the entire kernel string. While underlying WebGPU engines like Dawn might have their own caching mechanisms, we implement a library-level cache for them as well.</p>

<h4 id="compute-pipelines">Compute Pipelines</h4>

<p>The cache key for a <code class="language-plaintext highlighter-rouge">GPUComputePipeline</code> is derived from its descriptor object. Since the <code class="language-plaintext highlighter-rouge">GPUPipelineLayout</code> and <code class="language-plaintext highlighter-rouge">GPUShaderModule</code> are cached separately, we can reuse their cache keys to optimize the key generation for the pipeline itself.</p>

<p>A <code class="language-plaintext highlighter-rouge">__cacheKey</code> property is stored on cacheable objects, and this key is used during stringification to avoid deep, recursive serialization.</p>

<h3 id="cache-statistics">Cache Statistics</h3>

<p>The caches collect hit and miss statistics to help understand their effectiveness.</p>

<p>Example output from statistics collection:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cache hits/misses:
Pipeline layouts: 7/1
Bind group layouts: 0/1
Compute modules: 4/4
Compute pipelines: 4/4
</code></pre></div></div>

<h3 id="measuring-performance-with-cpu-timing">Measuring Performance with CPU Timing</h3>

<p>To measure the performance impact of caching, enable CPU timing. This will wait for the GPU to finish its work and then record the CPU time taken.</p>

<p>(TODO: move this into the timing article)</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">commandBuffer</span> <span class="o">=</span> <span class="nx">encoder</span><span class="p">.</span><span class="nx">finish</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="nx">args</span><span class="p">?.</span><span class="nx">enableCPUTiming</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">await</span> <span class="k">this</span><span class="p">.</span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">onSubmittedWorkDone</span><span class="p">();</span>
  <span class="k">this</span><span class="p">.</span><span class="nx">cpuStartTime</span> <span class="o">=</span> <span class="nx">performance</span><span class="p">.</span><span class="nx">now</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">this</span><span class="p">.</span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">submit</span><span class="p">([</span><span class="nx">commandBuffer</span><span class="p">]);</span>

<span class="k">if</span> <span class="p">(</span><span class="nx">args</span><span class="p">?.</span><span class="nx">enableCPUTiming</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">await</span> <span class="k">this</span><span class="p">.</span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">onSubmittedWorkDone</span><span class="p">();</span>
  <span class="k">this</span><span class="p">.</span><span class="nx">cpuEndTime</span> <span class="o">=</span> <span class="nx">performance</span><span class="p">.</span><span class="nx">now</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Learn about Gridwise's caching strategy for WebGPU objects to improve performance while balancing overhead costs.]]></summary></entry><entry><title type="html">Gridwise Architecture</title><link href="http://localhost:4000/gridwise/docs/2025/08/12/architecture/" rel="alternate" type="text/html" title="Gridwise Architecture" /><published>2025-08-12T00:00:00-04:00</published><updated>2025-08-12T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/08/12/architecture</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/08/12/architecture/"><![CDATA[<p>The primary goal of Gridwise is to deliver best-in-class performance on WebGPU compute primitives while minimizing the amount of code that must be written by the library user. Ideally, a Gridwise user will declare and then execute a primitive and Gridwise will handle all low-level details of setting up and calling the necessary WebGPU primitives.</p>

<h2 id="gridwise-abstraction">Gridwise Abstraction</h2>

<h3 id="primitive">Primitive</h3>

<p>The primary abstraction in Gridwise is a <code class="language-plaintext highlighter-rouge">Primitive</code>. Primitives are instances of a primitive-specific subclass of a JavaScript <code class="language-plaintext highlighter-rouge">Primitive</code> class. They have an <code class="language-plaintext highlighter-rouge">execute</code> member function, and the typical usage is to instantiate a primitive using <code class="language-plaintext highlighter-rouge">new()</code> and then call <code class="language-plaintext highlighter-rouge">execute()</code> on that primitive. Both instantiation and execution have numerous options. As an example, let’s look at a scan primitive, which is an instance of the <code class="language-plaintext highlighter-rouge">DLDFScan</code> class (“decoupled-lookback, decoupled-fallback scan”):</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">datatype</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">u32</span><span class="dl">"</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">dldfscanPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">DLDFScan</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">binop</span><span class="p">:</span> <span class="k">new</span> <span class="nx">BinOpAdd</span><span class="p">({</span> <span class="nx">datatype</span> <span class="p">}),</span>
  <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">exclusive</span><span class="dl">"</span><span class="p">,</span> <span class="c1">// "exclusive" is the default</span>
  <span class="nx">datatype</span><span class="p">,</span>
<span class="p">});</span>

<span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="nx">inputBuffer</span><span class="p">,</span>
  <span class="nx">outputBuffer</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<p>This particular primitive is parameterized by its datatype (in this case, “u32”), by the binary operation (“binop”) performed by the scan (in this case, addition on u32 data), and by the scan operation (exclusive or inclusive).</p>

<p>When the scan is actually executed, its arguments are buffers that store its input and output. This particular primitive has named arguments of an input buffer named <code class="language-plaintext highlighter-rouge">inputBuffer</code> and an output buffer named <code class="language-plaintext highlighter-rouge">outputBuffer</code>. These buffers can be WebGPU buffers of type <code class="language-plaintext highlighter-rouge">GPUBuffer</code> but can also be <code class="language-plaintext highlighter-rouge">Buffer</code>s, described next.</p>

<p>The primitive performs all necessary WebGPU operations, including (optionally) setting up an encoder, building up and setting WebGPU layouts and pipelines, running the pipeline, and optionally recording GPU-side or CPU-side timing. It also caches WebGPU layouts and pipelines to avoid the expense of recreating them if they have already been created.</p>

<h3 id="buffer">Buffer</h3>

<p>One of the challenges of writing a primitive library is handling data, which may be stored on the CPU (in a JavaScript typed array) or on the GPU (as a WebGPU GPUBuffer). Gridwise’s <code class="language-plaintext highlighter-rouge">Buffer</code> class attempts to abstract away the details of separately managing CPU and GPU buffer data structures with one unified data structure that stores, and moves data between, both. This data structure has grown organically to handle many use cases and deserves more focus by future developers as a principled data structure in WebGPU programming.</p>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Overview of Gridwise's core architecture designed to deliver best-in-class WebGPU compute performance with minimal code.]]></summary></entry><entry><title type="html">Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function</title><link href="http://localhost:4000/gridwise/docs/2025/04/08/writing-a-webgpu-wgsl-workgroup-reduce-function/" rel="alternate" type="text/html" title="Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function" /><published>2025-04-08T00:00:00-04:00</published><updated>2025-04-08T00:00:00-04:00</updated><id>http://localhost:4000/gridwise/docs/2025/04/08/writing-a-webgpu-wgsl-workgroup-reduce-function</id><content type="html" xml:base="http://localhost:4000/gridwise/docs/2025/04/08/writing-a-webgpu-wgsl-workgroup-reduce-function/"><![CDATA[<h2 id="summary-of-pain-points">Summary of Pain Points</h2>

<p>When writing a generic library function in WGSL, we identified several key difficulties:</p>

<ul>
  <li><strong>Explicit Built-in Declarations:</strong> WGSL’s requirement to explicitly declare <code class="language-plaintext highlighter-rouge">@builtins</code> complicates APIs.</li>
  <li><strong>Inconsistent Built-in Variants:</strong> Not all built-ins have both 3D and 1D variants.</li>
  <li><strong>Module-Scoped Workgroup Memory:</strong> Declaring workgroup memory only at the module scope harms modularity.</li>
  <li><strong>Lack of Generics:</strong> The absence of function overloading or templating makes it difficult to write generic APIs.</li>
</ul>

<p>These limitations lead to a choice between two library design patterns: a few complex kernels using template-literal string pasting, or many simple kernels using metaprogramming.</p>

<hr />

<h2 id="scenario-a-reduceworkgroup-function">Scenario: A reduceWorkgroup Function</h2>

<p>We will focus on creating a <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function that will be incorporated into a primitive library. We expect external users will face a need to input a linear array of data and have each workgroup compute the sum of a sub-section of that data. Our implementation, as part of a library, will allow them to do so without concern for how the reduction is implemented.</p>

<p>The semantics of the function are as follows: consider a workgroup of N invocations (e.g., N = 128); workgroup W will compute the sum of <code class="language-plaintext highlighter-rouge">input[W*N:W*(N+1))</code>, and each invocation in the workgroup will receive this sum as the return value of a function call.</p>

<h3 id="desired-function-call-caller-wgsl-definition">Desired Function Call: Caller (WGSL Definition)</h3>

<p>Ideally, making the function call from within a WGSL kernel would be simple, with the minimal call looking something like</p>

<pre><code class="language-wgsl">...
val = reduceWorkgroup(ptr);
...
</code></pre>

<p>Here we assume that <code class="language-plaintext highlighter-rouge">ptr</code> is an address pointing to an item within a linear input array, and that the private variable <code class="language-plaintext highlighter-rouge">val</code> and the deferenced value at <code class="language-plaintext highlighter-rouge">ptr</code> have the same datatype. If the workgroup has <code class="language-plaintext highlighter-rouge">W</code> invocations, then <code class="language-plaintext highlighter-rouge">val</code>, for every invocation in workgroup <code class="language-plaintext highlighter-rouge">W</code>, will assume the value <code class="language-plaintext highlighter-rouge">reduce(ptr[W*N:W*(N+1)))</code>.</p>

<p>This interface does not specify the reduction operation (for instance, addition, max, or min), nor the datatype. Possible options to address the former include:</p>

<ul>
  <li>A separate reduction function for each operation (<code class="language-plaintext highlighter-rouge">reduceAddWorkgroup</code>, <code class="language-plaintext highlighter-rouge">reduceMinWorkgroup</code>, etc.)</li>
  <li>A default operation (e.g., <code class="language-plaintext highlighter-rouge">add</code>)</li>
  <li>Separately defining an operation (a “binop” == a monoid) that must be explicitly set by the caller and implicitly used by the function</li>
</ul>

<p>However, we do not further discuss this issue in this document.</p>

<h3 id="desired-function-call-callee">Desired Function Call: Callee</h3>

<p>We would also like the callee function/kernel to be as simple as possible. The minimum kernel that calls our function, and places the output into an output array, would look something like this:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u
) {
  let r = reduceWorkgroup(&amp;in);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<h3 id="issues-with-the-above-kernel">Issues with the above kernel</h3>

<h4 id="builtins-must-be-explicitly-declared">Builtins must be explicitly declared</h4>

<p>The above kernel has 5 lines of code. 2 of them are declaring built-ins. WGSL requires these declarations, but other languages have made different choices. Why are variables like <code class="language-plaintext highlighter-rouge">local_invocation_index</code> and <code class="language-plaintext highlighter-rouge">workgroup_id</code> not available within a kernel without the need for these declarations?</p>

<p>Possible ways to remove the need for these declarations include</p>

<ul>
  <li>Making a builtin variable available within kernels (e.g., CUDA’s <code class="language-plaintext highlighter-rouge">threadIdx</code>)</li>
  <li>Making a function call that retrieves a builtin variable available within kernels (e.g., SYCL’s <code class="language-plaintext highlighter-rouge">get_id()</code>)</li>
</ul>

<h4 id="some-3d-builtins-lack-a-1d-variant">Some 3D builtins lack a 1D variant</h4>

<p>The use of <code class="language-plaintext highlighter-rouge">wgid</code> above reflects a common implementation pattern: we logically have a 1D data space (<code class="language-plaintext highlighter-rouge">in</code>, <code class="language-plaintext highlighter-rouge">out</code>) and thus want our workgroups to also be organized as a 1D data space. However, the only access we have to the workgroup id is through a 3D builtin. Above, we just assume that such a builtin only uses the <code class="language-plaintext highlighter-rouge">.x</code> part of the <code class="language-plaintext highlighter-rouge">workgroup_id</code> builtin, but this assumption is checked nowhere.</p>

<p>It would be convenient to have a 1D builtin equivalent for every 3D builtin (specifically, WGSL lacks <code class="language-plaintext highlighter-rouge">workgroup_index</code> and <code class="language-plaintext highlighter-rouge">global_invocation_index</code>).</p>

<h3 id="implementing-reduceworkgroup">Implementing reduceWorkgroup</h3>

<p>Now let’s turn to actually implementing the <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function.</p>

<p>An initial, simple implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> might allocate an workgroup-memory variable and use <code class="language-plaintext highlighter-rouge">atomicAdd</code> to accumulate inputs into it. It might look like this:</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[?]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<h4 id="leaky-abstraction-wg_temp">Leaky abstraction: <code class="language-plaintext highlighter-rouge">wg_temp</code></h4>

<p>The above code uses storage <code class="language-plaintext highlighter-rouge">wg_temp</code> located in workgroup memory. WGSL requires that variables in the workgroup address space be declared at the module scope, which is a significant limitation on modularity. Who declares this storage? How big is it? Why can’t I declare it within the <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function?</p>

<p>We could declare the workgroup memory <code class="language-plaintext highlighter-rouge">wg_temp_reduceWorkgroup</code> at the module scope as follows:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp_reduceWorkgroup: array&lt;atomic&lt;u32&gt;, 1&gt;;
fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u,
                  ) -&gt; u32 {
  atomicAdd(&amp;wg_temp_reduceWorkgroup[0], input[?]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp_reduceWorkgroup[0]);
}
</code></pre>

<p>However, such a declaration by the writer of a library might have a name conflict for the workgroup memory <code class="language-plaintext highlighter-rouge">wg_temp_reduceWorkgroup</code>, either within the library or with a different allocation defined by the user of the library. Note that if we define many different <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> functions, for instance ones that are specialized to datatype and reduction operation, we also must declare a different workgroup memory variable for each of them. Then a compiler would have to identify which specialized functions are actually used and only instantiate their workgroup memory regions. Finally, while it is likely that a complex workload that used many different reduce functions from this library could potentially share the same workgroup memory region used for the accumulation, the above code would not allow this sharing.</p>

<p>We might consider a language change that allows workgroup memory to be declared within a function instead of at module scope. This potentially eliminates name conflicts. But the programmer still must account for the use of workgroup memory.</p>

<h4 id="specifying-the-input-region">Specifying the input region</h4>

<p>The above code has the line <code class="language-plaintext highlighter-rouge">atomicAdd(&amp;wg_temp[0], input[?])</code>. How do we fill in the <code class="language-plaintext highlighter-rouge">[?]</code>?</p>

<p>What we want is for each individual instance (thread) to fetch the input value that corresponds to its global instance id. Instance 0 fetches <code class="language-plaintext highlighter-rouge">input[0]</code>, instance 128 fetches <code class="language-plaintext highlighter-rouge">input[128]</code>, etc. This information is only available through a builtin, which requires that the enclosing kernel must input that builtin and that the function add an additional input:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(global_invocation_id) gid: vec3u,
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u) {
  let r = reduceWorkgroup(&amp;in, gid.x);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<p>While this second argument to <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> adds flexibility, it would be nice to not require the kernel author to plumb a builtin through the kernel if that builtin was used in the default way.</p>

<p>(Look at the use of <code class="language-plaintext highlighter-rouge">wgid.x</code> in the above kernel and recall the comment above that “It would be useful to have a 1D builtin equivalent for every 3D builtin (specifically, <code class="language-plaintext highlighter-rouge">workgroup_index</code> and <code class="language-plaintext highlighter-rouge">global_invocation_index</code>)”—here is a use for <code class="language-plaintext highlighter-rouge">workgroup_index</code>.)</p>

<h2 id="a-working-implementation">A Working Implementation</h2>

<p>Kernel (WGSL) code:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(global_invocation_id) gid: vec3u,
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u) {
  let r = reduceWorkgroup(&amp;in, gid.x);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<p>Implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp: array&lt;atomic&lt;u32&gt;, 1&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Note that nothing in the actual kernel itself is specific to datatype. (Or workgroup size, for that matter.)</p>

<h3 id="generalizing-our-implementation-">Generalizing our implementation …</h3>

<h4 id="-across-datatypes">… across datatypes</h4>

<p>So, as an experiment, let’s consider adding another <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function that reduces <code class="language-plaintext highlighter-rouge">f32</code> values rather than the <code class="language-plaintext highlighter-rouge">u32</code> values above. The callee code does not change, but the library function implementation does:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp: array&lt;atomic&lt;f32&gt;, 1&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;f32&gt;, read&gt;,
                   gid: vec3u) -&gt; f32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>This addition of an <code class="language-plaintext highlighter-rouge">f32 reduceWorkgroup</code> function uncovers two new issues:</p>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">wg_temp</code> workgroup variable now has a name collision between the <code class="language-plaintext highlighter-rouge">u32</code> variant and the <code class="language-plaintext highlighter-rouge">f32</code> variant.</li>
  <li>We now have two different functions named <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>, which is not permitted in WGSL. We can’t overload a function name. Type-specific dispatch would be useful here.</li>
</ul>

<p>The careful WGSL developer notices a third issue: there is no <code class="language-plaintext highlighter-rouge">atomicAdd</code> on <code class="language-plaintext highlighter-rouge">f32</code> variables.</p>

<p>The above issues motivate a library design that has different functions for each datatype, specifically here <code class="language-plaintext highlighter-rouge">reduceWorkgroupU32</code> and <code class="language-plaintext highlighter-rouge">reduceWorkgroupF32</code>.</p>

<h4 id="-across-storage-locations">… across storage locations</h4>

<p>Recall that our <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> signature shows that the input data is located in global (storage) memory:</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Let’s consider a <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> that instead stored its input in workgroup memory. It would be ideal if we could support inputs in either global (storage) or workgroup memory without any changes to the code.</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;workgroup, array&lt;u32&gt;, SIZE&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Note that the <em>bodies</em> of these two functions are identical; only the argument type is different. Nonetheless WGSL requires we implement both functions separately because they have different argument types. This argues for a library designer separately implementing <code class="language-plaintext highlighter-rouge">reduceWorkgroupWGU32</code> and <code class="language-plaintext highlighter-rouge">reduceWorkgroupStorageU32</code>.</p>

<h2 id="a-more-realistic-workgroup-reduce-function">A More Realistic Workgroup Reduce Function</h2>

<p>The above functions are simple but not high-performance, because all instances must serialize on the atomic reduction variable. Higher-performance reduce implementations instead exploit parallelism across instances within a workgroup. As well, the highest-performance implementations will likely make use of WebGPU subgroups.</p>

<p>One of the challenges of subgroups is that their size is not constant within WebGPU. In fact, different kernels running within the same application on some WebGPU-capable hardware may not even share the same subgroup size. If we wish to write a subgroup-size-agnostic kernel, we must support all possible subgroup sizes within that kernel. The challenge with such an implementation is that any allocation that depends on the subgroup size must perform a worst-case allocation that works with any subgroup size.</p>

<p>WebGPU provides two adapter properties—<code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code> and <code class="language-plaintext highlighter-rouge">MAX_SUBGROUP_SIZE</code>—that we can use to perform allocations. Below is the start of a high-performance workgroup-reduce kernel that requires a workgroup-memory allocation for partial reductions. The size of the workgroup-memory allocation is directly proportional to the workgroup size (variable: <code class="language-plaintext highlighter-rouge">{$workgroupSize}</code>) and inversely proportional to the subgroup size (variable: <code class="language-plaintext highlighter-rouge">${MIN_SUBGROUP_SIZE}</code>).</p>

<pre><code class="language-wgsl">const BLOCK_DIM: u32 = ${workgroupSize};
const TEMP_WG_MEM_SIZE = BLOCK_DIM / ${MIN_SUBGROUP_SIZE};
var&lt;workgroup&gt; wg_temp: array&lt;u32, TEMP_WG_MEM_SIZE&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u, lidx: u32, sgid: u32, sgsz: u32
                   ) -&gt; u32 {
  let sid = lidx / sgsz;
  let lane_log = u32(countTrailingZeros(sgsz)); /* log_2(sgsz) */
  let local_spine: u32 = BLOCK_DIM &gt;&gt; lane_log;
  /* BLOCK_DIM / subgroup size; how many partial reductions in this tile? */
  // ...
}
</code></pre>

<p>The value of <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code> (and more broadly, any value that is adapter-dependent and thus not determinable until runtime) has two impacts on this code:</p>

<ul>
  <li>First, the allocation is inversely proportional to <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code>. We would like to only allocate the memory we need. It is not clear in WGSL what the right way to perform this specialization might be: static (compile-time) specialization, such as what a C++ template provides, or instead runtime compilation that incorporates the adapter property.</li>
  <li>Second, the algorithm can be made simpler if the subgroup sizes are large enough (specifically, if <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE * MIN_SUBGROUP_SIZE &gt;= workgroupSize</code>). It would be desirable to have the maximum possible compile-time specialization for such a decision rather than making all aspects of the decision at runtime.</li>
</ul>

<p>In summary, the presence of an adapter-specific property, only discoverable at runtime, mandates making runtime decisions that developers would prefer to do at compile time.</p>

<h2 id="multiple-implementations-are-interesting-but-builtins-complicate-function-signatures">Multiple implementations are interesting, but builtins complicate function signatures</h2>

<p>It would be desirable for a library user to write code that could call <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> but not have to choose which implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>; instead, that choice could be made by the underlying library in some static or runtime-dependent way. This ability would also be useful for the library developer, who might want to try different <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> implementations in real workloads to determine the fastest one without having to change the function call within the workload. However, if each <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> implementation had a different function signature, this would be impossible.</p>

<p>Unfortunately, the function signatures of different implementations of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> (above) are different.</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32
</code></pre>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u, lidx: u32, sgid: u32, sgsz: u32
                   ) -&gt; u32
</code></pre>

<p>The difference is which builtins are used. Builtins must be passed in through the function signature, and if different implementations use a different set of builtins, their function signatures will differ.</p>

<p>One remedy is to pass every builtin into every function. This is verbose and quite kludgey. Instead we have addressed this problem by …</p>

<h3 id="packing-built-ins-into-structs">Packing Built-ins into Structs</h3>

<p>To simplify the function signatures, we pack built-ins into structs:</p>

<p>Code snippet</p>

<pre><code class="language-wgsl">struct Builtins {
 @builtin(global_invocation_id) gid: vec3u,
 @builtin(num_workgroups) nwg: vec3u,
 @builtin(workgroup_id) wgid: vec3u,
 @builtin(local_invocation_index) lidx: u32,
 @builtin(local_invocation_id) lid: vec3u,
 @builtin(subgroup_size) sgsz: u32,
 @builtin(subgroup_invocation_id) sgid: u32
}
</code></pre>

<p>We also divide those builtins into two different structs, differentiated by whether the member is uniform or non-uniform. The use of <code class="language-plaintext highlighter-rouge">BuiltinsUniform</code> is sometimes necessary to ensure workgroup or subgroup uniformity.</p>

<pre><code class="language-wgsl">struct BuiltinsNonuniform {
  @builtin(global_invocation_id) gid: vec3u /* 3D thread id in compute shader grid */,
  @builtin(local_invocation_index) lidx: u32 /* 1D thread index within workgroup */,
  @builtin(local_invocation_id) lid: vec3u /* 3D thread index within workgroup */,
  @builtin(subgroup_invocation_id) sgid: u32 /* 1D thread index within subgroup */
}

struct BuiltinsUniform {
  @builtin(num_workgroups) nwg: vec3u /* == dispatch */,
  @builtin(workgroup_id) wgid: vec3u /* 3D workgroup id within compute shader grid */,
  @builtin(subgroup_size) sgsz: u32 /* subgroup size */
}
</code></pre>

<p>This allows for a cleaner function signature, but mandates that the library user must use the library’s naming conventions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We conclude by reiterating the main pain points in WGSL that make writing generic compute libraries challenging:</p>

<ul>
  <li>Explicit declaration of @builtins.</li>
  <li>Lack of 1D variants for all built-ins.</li>
  <li>Module-scoped workgroup memory.</li>
  <li>Lack of function overloading and templating.</li>
</ul>

<p>These limitations force library designers to choose between metaprogramming to generate many specialized functions or using template literals to create a few complex kernels.</p>]]></content><author><name></name></author><category term="docs" /><summary type="html"><![CDATA[Explore the challenges of writing generic WGSL library functions, including builtin declarations and workgroup memory limitations.]]></summary></entry></feed>